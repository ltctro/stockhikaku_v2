import streamlit as st

import streamlit as st

if "authed" not in st.session_state:
    st.session_state.authed = False

if not st.session_state.authed:
    pw = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if pw == st.secrets["nrsk"]:
        st.session_state.authed = True
        st.experimental_rerun()
    else:
        st.stop()

import yfinance as yf
import pandas as pd
import requests
import plotly.graph_objects as go
import sqlite3
import json
import os
from datetime import datetime, timedelta
from bs4 import BeautifulSoup


st.set_page_config(page_title="æ ªä¾¡æ¯”è¼ƒ ï¼‹ æŠ•è³‡å®¶å¿ƒç†æŒ‡æ¨™", layout="wide")

# ==============================
# ðŸ’¾ DB è¨­å®šï¼ˆmarket_cache.db ã«ä¿å­˜ï¼‰
# ==============================
DB_PATH = "market_cache.db"
STOCKS_CACHE_FILE = "stocks_cache.json"

def fetch_all_stocks():
    """yfinance ã‹ã‚‰ä¸Šå ´éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆåˆå›žã®ã¿ï¼‰"""
    # æ—¥æœ¬æ ª ã¨ ç±³å›½å¤§åž‹æ ªã‚’å–å¾—
    default_stocks = {
        # æ—¥æœ¬ - ä¸»è¦éŠ˜æŸ„
        "7203": "ãƒˆãƒ¨ã‚¿", "7267": "ãƒ›ãƒ³ãƒ€", "7201": "æ—¥ç”£", "6502": "æ±èŠ", "6758": "ã‚½ãƒ‹ãƒ¼",
        "7974": "ä»»å¤©å ‚", "6954": "ãƒ•ã‚¡ãƒŠãƒƒã‚¯", "6981": "æ‘ç”°è£½ä½œæ‰€", "6902": "ãƒ‡ãƒ³ã‚½ãƒ¼",
        "9432": "NTT", "9433": "KDDI", "9434": "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯", "8306": "æ—¥æœ¬éŠ€è¡Œ",
        "8308": "ã‚Šããª", "8309": "ä¸‰è±UFJ", "8314": "ä¸‰äº•ä½å‹FG", "8801": "ä¸‰äº•ä¸å‹•ç”£",
        "8802": "ä¸‰è±åœ°æ‰€", "8031": "ä¸‰äº•ç‰©ç”£", "8058": "ä¸‰è±å•†äº‹", "8591": "ã‚ªãƒªãƒƒã‚¯ã‚¹",
        "2002": "æ—¥æ¸…è£½ç²‰", "2222": "å¯¿ã‚¹ãƒ”ãƒªãƒƒãƒ„", "4503": "ã‚¢ã‚¹ãƒ†ãƒ©ã‚¹è£½è–¬", "4578": "å¤§å¡š",
        "4661": "ã‚ªãƒªãƒ³ãƒ‘ã‚¹", "1833": "æ—­åŒ–æˆ", "4183": "ä¸‰è±ã‚±ãƒŸã‚«ãƒ«", "5411": "JFEã‚¹ãƒãƒ¼ãƒ«",
        "6367": "ãƒ€ã‚¤ã‚­ãƒ³", "7731": "ãƒ‹ã‚³ãƒ³", "8113": "ãƒ•ã‚¡ãƒŸãƒž", "3382": "ã‚»ãƒ–ãƒ³ã‚¢ã‚¤",
        "2914": "JT", "1963": "æ—¥æœ¬ãƒ‘ã‚¤ãƒ—", "2170": "ãƒªãƒ³ãƒ†ãƒƒã‚¯", "6326": "ã‚¯ãƒœã‚¿",
        "9766": "é–¢è¥¿é›»åŠ›", "9513": "é›»æºé–‹ç™º", "4005": "æ˜­å’Œé›»å·¥", "2768": "åŒæ—¥",
        "9461": "ç™¾äº”éŠ€è¡Œ", "1820": "ãƒ«ãƒŸãƒŠã‚¹", "8725": "äº¬çŽ‹é›»é‰„", "9020": "JRæ±æ—¥æœ¬",
        "5108": "ãƒ–ãƒªãƒ‚ã‚¹ãƒˆãƒ³", "7012": "å·å´Žé‡å·¥", "7272": "ãƒ¤ãƒžãƒç™º", "5214": "æ—¥æœ¬é›»æ°—ç¡å­",
        "6645": "ã‚ªãƒ ãƒ­ãƒ³", "6674": "ã‚¸ã‚ªãƒžãƒ†ãƒƒã‚¯", "7741": "HOYA", "9022": "è¿‘é‰„ã‚°ãƒ«ãƒ¼ãƒ—",
        "9101": "æ—¥æœ¬éƒµèˆ¹", "9104": "å•†èˆ¹ä¸‰äº•", "9107": "å·å´Žæ±½èˆ¹", "6098": "ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ",
        "3086": "J.ãƒ•ãƒ­ãƒ³ãƒˆ", "8252": "ä¸¸äº•ã‚°ãƒ«ãƒ¼ãƒ—", "8233": "é«˜å³¶å±‹", "9984": "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯",
        "6701": "NEC", "8630": "é‡Žæ‘è¨¼åˆ¸", "8633": "å¤§å’Œè¨¼åˆ¸", "6869": "ã‚·ã‚¹ãƒ¡ãƒƒã‚¯ã‚¹",
        "4755": "æ¥½å¤©", "9999": "ä¼šç¤¾A",  # ãƒ€ãƒŸãƒ¼
        # ç±³å›½ - ä¸»è¦ 500
        "AAPL": "Apple", "MSFT": "Microsoft", "GOOGL": "Google", "AMZN": "Amazon",
        "NVDA": "Nvidia", "META": "Meta", "TSLA": "Tesla", "BRK.B": "Berkshire",
        "JPM": "JPMorgan", "V": "Visa", "JNJ": "J&J", "WMT": "Walmart",
        "MA": "Mastercard", "PG": "Procter", "PYPL": "PayPal", "INTC": "Intel",
        "AMD": "AMD", "CSCO": "Cisco", "ORCL": "Oracle", "IBM": "IBM",
        "ADBE": "Adobe", "CRM": "Salesforce", "NFLX": "Netflix", "DIS": "Disney",
        "BA": "Boeing", "CAT": "Caterpillar", "GE": "GE", "HON": "Honeywell",
        "MMM": "3M", "LMT": "Lockheed", "RTX": "Raytheon", "TXN": "Texas Inst",
        "QCOM": "Qualcomm", "AVGO": "Broadcom", "MU": "Micron", "CRM": "Salesforce",
        "COIN": "Coinbase", "NFLX": "Netflix", "ROKU": "Roku", "SPOT": "Spotify",
        "ZM": "Zoom", "SHOP": "Shopify", "UBER": "Uber", "LYFT": "Lyft",
        "ARKK": "Ark Innovation", "QQQ": "Nasdaq 100", "SPY": "S&P 500", "IVV": "iShares",
        "XOM": "ExxonMobil", "CVX": "Chevron", "COP": "ConocoPhillips", "EOG": "EOG",
        "MPC": "Marathon", "PSX": "Phillips 66", "SLB": "Schlumberger", "HAL": "Halliburton",
        "FDX": "FedEx", "UPS": "UPS", "DAL": "Delta", "UAL": "United",
        "LUV": "Southwest", "AAL": "American", "ALK": "Alaska", "SAVE": "Spirit",
        "MGM": "MGM", "WYNN": "Wynn", "LVS": "Las Vegas", "CZR": "Caesars",
        "HLT": "Hilton", "RCL": "Royal", "CCL": "Carnival", "F": "Ford",
        "GM": "GM", "TM": "Toyota", "HMC": "Honda", "SNE": "Sony", "TSM": "TSMC",
        "ASML": "ASML", "SAP": "SAP", "UBER": "Uber", "AI": "C3 Metrics",
        "MSTR": "MicroStrategy", "RIOT": "Riot", "MARA": "Marathon Digital",
        "SQ": "Block", "HOOD": "Robinhood", "TD": "TD", "RY": "RBC",
        "BNS": "BMO", "CM": "CIBC", "EIF": "Empire State", "BBY": "Best Buy",
        "TGT": "Target", "COST": "Costco", "HD": "Home Depot", "LOW": "Lowe's",
        "NKE": "Nike", "MCD": "McDonald's", "SBUX": "Starbucks", "YUM": "Yum",
        "CMG": "Chipotle", "KO": "Coca-Cola", "PEP": "PepsiCo", "MDLZ": "Mondelez",
        "KHC": "Kraft", "TSCO": "Tractor", "LB": "L Brands", "GPS": "Gap",
        "AZO": "AutoZone", "O": "Realty", "PLD": "Prologis", "AMT": "American",
        "CCI": "Crown", "DLR": "Digital", "EQIX": "Equinix", "UNIT": "Uniti",
    }
    return default_stocks

def load_stocks_from_cache():
    if os.path.exists(STOCKS_CACHE_FILE):
        try:
            with open(STOCKS_CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    stocks = fetch_all_stocks()
    with open(STOCKS_CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(stocks, f, ensure_ascii=False, indent=2)
    return stocks

def init_db():
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("CREATE TABLE IF NOT EXISTS price_cache (ticker TEXT, date TEXT, close REAL, volume REAL, PRIMARY KEY (ticker, date))")
    cur.execute("CREATE TABLE IF NOT EXISTS fear_greed (date TEXT PRIMARY KEY, value INTEGER)")
    cur.execute("CREATE TABLE IF NOT EXISTS ticker_cache (ticker TEXT PRIMARY KEY, name TEXT, cached_at TEXT)")
    
    cur.execute("SELECT COUNT(*) FROM ticker_cache")
    if cur.fetchone()[0] == 0:
        stocks = load_stocks_from_cache()
        ts = datetime.today().isoformat()
        cur.executemany("INSERT OR REPLACE INTO ticker_cache VALUES (?, ?, ?)", [(k, v, ts) for k, v in stocks.items()])
        conn.commit()
    conn.close()

def save_prices(ticker: str, df: pd.DataFrame):
    if df is None or df.empty: return
    conn = sqlite3.connect(DB_PATH)
    rows = [(ticker, idx.strftime("%Y-%m-%d"), float(row['Close']), float(row['Volume'])) for idx, row in df.iterrows()]
    conn.executemany("INSERT OR REPLACE INTO price_cache VALUES (?, ?, ?, ?)", rows)
    conn.commit()
    conn.close()

def load_prices_from_db(ticker: str, start_date: str) -> pd.DataFrame:
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query("SELECT date, close as Close, volume as Volume FROM price_cache WHERE ticker = ? AND date >= ? ORDER BY date", conn, params=(ticker, start_date))
    conn.close()
    if df.empty: return pd.DataFrame()
    df['date'] = pd.to_datetime(df['date'])
    return df.set_index('date')

def update_price_if_needed(ticker: str, period: str = "1y") -> pd.DataFrame:
    init_db()
    today = datetime.today().date()
    mapping = {"1y": 365, "3y": 1095, "5y": 1825, "10y": 3650, "max": 10000}
    days = mapping.get(period, 365)
    start_date = (today - timedelta(days=days)).strftime("%Y-%m-%d")
    
    local = load_prices_from_db(ticker, start_date)
    if local.empty or local.index.max().date() < today:
        try:
            df_new = yf.Ticker(ticker).history(period=period)
            if df_new is not None and not df_new.empty:
                df_new.index = pd.to_datetime(df_new.index).tz_localize(None)
                save_prices(ticker, df_new)
                return load_prices_from_db(ticker, start_date)
        except:
            pass
    return local

@st.cache_data
def get_company_name(ticker: str) -> str:
    try:
        info = yf.Ticker(ticker).info
        return info.get('longName') or info.get('shortName') or ticker
    except:
        return ticker

@st.cache_data
def get_financial_metrics(ticker: str) -> dict:
    try:
        # ðŸ‡¯ðŸ‡µ æ—¥æœ¬æ ª
        if ticker.endswith(".T"):
            code = ticker.replace(".T","")

            j = requests.get(
                f"https://irbank.net/{code}/metrics.json",
                timeout=10
            ).json()

            return {
                "PER": j.get("PER"),
                "PBR": j.get("PBR"),
                "sector": yf.Ticker(ticker).info.get("sector","Unknown")
            }

        # ðŸ‡ºðŸ‡¸ ç±³å›½æ ª
        info = yf.Ticker(ticker).info
        return {
            "PER": info.get("trailingPE"),
            "PBR": info.get("priceToBook"),
            "sector": info.get("sector","Unknown")
        }

    except:
        return {"PER": None, "PBR": None, "sector": "Unknown"}


def search_tickers(query: str) -> dict:
    query_lower = query.lower().strip()
    if not query_lower: return {}
    results = {}
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query("SELECT ticker, name FROM ticker_cache WHERE LOWER(ticker) LIKE ? OR LOWER(name) LIKE ? LIMIT 15", 
                           conn, params=(f"%{query_lower}%", f"%{query_lower}%"))
    conn.close()
    for _, row in df.iterrows():
        results[row['ticker']] = row['name']
    return results

def load_fear_greed_cached() -> pd.DataFrame:
    try:
        url = "https://api.alternative.me/fng/?limit=0&format=json"
        res = requests.get(url, timeout=10).json()
        df = pd.DataFrame(res.get("data", []))
        df["date"] = pd.to_datetime(df["timestamp"].astype(int), unit="s")
        df["Value"] = df["value"].astype(int)
        return df.set_index('date')[['Value']].sort_index()
    except:
        return pd.DataFrame()

# ============================
# UIéƒ¨åˆ†
# ============================
st.title("ðŸ“ˆ æ ªä¾¡æ¯”è¼ƒ ï¼‹ æŠ•è³‡å®¶å¿ƒç†æŒ‡æ¨™")

if "selected_tickers" not in st.session_state:
    st.session_state.selected_tickers = []

search_query = st.text_input("éŠ˜æŸ„æ¤œç´¢ (ä¾‹: ãƒˆãƒ¨ã‚¿, 5020, Apple)")
if search_query:
    results = search_tickers(search_query)
    for symbol, name in results.items():
        if st.button(f"è¿½åŠ : {symbol} - {name}", key=f"add_{symbol}"):
            ticker = f"{symbol}.T" if symbol.isdigit() else symbol
            if ticker not in st.session_state.selected_tickers:
                st.session_state.selected_tickers.append(ticker)
            st.rerun()

if st.session_state.selected_tickers:
    st.write("**é¸æŠžä¸­:** " + ", ".join(st.session_state.selected_tickers))
    if st.button("é¸æŠžã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.selected_tickers = []
        st.rerun()

# æœŸé–“è¨­å®š
col1, col2, col3 = st.columns(3)
with col1:
    period = st.selectbox("æœŸé–“", ["1y", "3y", "5y", "10y", "max"], index=0)
with col2:
    base_date = st.date_input("åŸºæº–æ—¥", value=datetime.today() - timedelta(days=365))
with col3:
    end_date = st.date_input("çµ‚äº†æ—¥", value=datetime.today())

sentiment_catalog = {"VIXæŒ‡æ•°": "^VIX", "Fear & Greed Index": "FNG", "ç±³10å¹´å‚µåˆ©å›žã‚Š": "^TNX"}
selected_sentiments = st.multiselect("å¿ƒç†æŒ‡æ¨™", list(sentiment_catalog.keys()), default=["VIXæŒ‡æ•°"])

# ãƒ‡ãƒ¼ã‚¿é›†è¨ˆ
etf_data = {}
for ticker in st.session_state.selected_tickers:
    df = update_price_if_needed(ticker, period)
    df = df[(df.index >= pd.to_datetime(base_date)) & (df.index <= pd.to_datetime(end_date))]
    if not df.empty:
        df["Relative"] = df["Close"] / df["Close"].iloc[0]
        etf_data[ticker] = df

# å¿ƒç†æŒ‡æ¨™
sentiment_data = {}
for name in selected_sentiments:
    code = sentiment_catalog[name]
    if code == "FNG":
        df = load_fear_greed_cached()
    else:
        df = update_price_if_needed(code, period)
        if not df.empty: df["Value"] = df["Close"]
    
    if not df.empty:
        sentiment_data[name] = df[(df.index >= pd.to_datetime(base_date)) & (df.index <= pd.to_datetime(end_date))]

# ã‚°ãƒ©ãƒ•
if etf_data or sentiment_data:
    fig = go.Figure()
    for t, df in etf_data.items():
        fig.add_trace(go.Scatter(x=df.index, y=df["Relative"], name=t, yaxis="y1"))
    
    for n, df in sentiment_data.items():
        fig.add_trace(go.Scatter(x=df.index, y=df["Value"], name=n, yaxis="y2", line=dict(dash='dot')))

    fig.update_layout(
        yaxis=dict(title="ç›¸å¯¾æ ªä¾¡"),
        yaxis2=dict(title="å¿ƒç†æŒ‡æ¨™", overlaying="y", side="right"),
        hovermode="x unified"
    )
    st.plotly_chart(fig, use_container_width=True)

# æŒ‡æ¨™ãƒ†ãƒ¼ãƒ–ãƒ«
if etf_data:
    st.subheader("ðŸ“Š è²¡å‹™æŒ‡æ¨™ã¾ã¨ã‚")
    metrics_list = []
    for t in st.session_state.selected_tickers:
        m = get_financial_metrics(t)
        df = etf_data.get(t)
        perf = f"{(df['Relative'].iloc[-1]-1)*100:+.2f}%" if df is not None else "N/A"
        metrics_list.append({
            "éŠ˜æŸ„": t,
            "ã‚»ã‚¯ã‚¿ãƒ¼": m['sector'],
            "PER": m['PER'],
            "PBR": m['PBR'],
            "æœŸé–“é¨°è½çŽ‡": perf
        })
    st.table(metrics_list)


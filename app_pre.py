import streamlit as st
st.set_page_config(page_title="æ ªä¾¡æ¯”è¼ƒ + æŠ•è³‡å®¶å¿ƒç†æŒ‡æ¨™", layout="wide")

api_key = st.secrets["FMP_API_KEY"]

# Secrets ã‹ã‚‰ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
APP_PASSWORD = st.secrets["APP_PASSWORD"]

# ğŸ” simple password lock
if "auth" not in st.session_state:
    st.session_state.auth = False

if not st.session_state.auth:
    st.title("ğŸ”’ Private Access")
    pwd = st.text_input("Password", type="password")
    if pwd == APP_PASSWORD:
        st.session_state.auth = True
        st.rerun()
    else:
        st.stop()

import yfinance as yf
import pandas as pd
import requests
import plotly.graph_objects as go
import sqlite3
import json
import os
from datetime import datetime, timedelta


# ==============================
# ğŸ’¾ DB è¨­å®š(market_cache.db ã«ä¿å­˜)
# ==============================
DB_PATH = "market_cache.db"
STOCKS_CACHE_FILE = "stocks_cache.json"

def fetch_all_stocks():
    """yfinance ã‹ã‚‰ä¸Šå ´éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—(åˆå›ã®ã¿)"""
    # æ—¥æœ¬æ ª ã¨ ç±³å›½å¤§å‹æ ªã‚’å–å¾—
    default_stocks = {
        # æ—¥æœ¬ - ä¸»è¦éŠ˜æŸ„
        "7203": "ãƒˆãƒ¨ã‚¿", "7267": "ãƒ›ãƒ³ãƒ€", "7201": "æ—¥ç”£", "6502": "æ±èŠ", "6758": "ã‚½ãƒ‹ãƒ¼",
        "7974": "ä»»å¤©å ‚", "6954": "ãƒ•ã‚¡ãƒŠãƒƒã‚¯", "6981": "æ‘ç”°è£½ä½œæ‰€", "6902": "ãƒ‡ãƒ³ã‚½ãƒ¼",
        "9432": "NTT", "9433": "KDDI", "9434": "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯", "8306": "æ—¥æœ¬éŠ€è¡Œ",
        "8308": "ã‚Šããª", "8309": "ä¸‰è±UFJ", "8314": "ä¸‰äº•ä½å‹FG", "8801": "ä¸‰äº•ä¸å‹•ç”£",
        "8802": "ä¸‰è±åœ°æ‰€", "8031": "ä¸‰äº•ç‰©ç”£", "8058": "ä¸‰è±å•†äº‹", "8591": "ã‚ªãƒªãƒƒã‚¯ã‚¹",
        "2002": "æ—¥æ¸…è£½ç²‰", "2222": "å¯¿ã‚¹ãƒ”ãƒªãƒƒãƒ„", "4503": "ã‚¢ã‚¹ãƒ†ãƒ©ã‚¹è£½è–¬", "4578": "å¤§å¡š",
        "4661": "ã‚ªãƒªã‚¨ãƒ³ã‚¿ãƒ«ãƒ©ãƒ³ãƒ‰", "1833": "æ—­åŒ–æˆ", "4183": "ä¸‰è±ã‚±ãƒŸã‚«ãƒ«", "5411": "JFEã‚¹ãƒãƒ¼ãƒ«",
        "6367": "ãƒ€ã‚¤ã‚­ãƒ³", "7731": "ãƒ‹ã‚³ãƒ³", "8113": "ãƒ•ã‚¡ãƒŸãƒ", "3382": "ã‚»ãƒ–ãƒ³ã‚¢ã‚¤",
        "2914": "JT", "1963": "æ—¥æœ¬ãƒ‘ã‚¤ãƒ—", "2170": "ãƒªãƒ³ãƒ†ãƒƒã‚¯", "6326": "ã‚¯ãƒœã‚¿",
        "9766": "é–¢è¥¿é›»åŠ›", "9513": "é›»æºé–‹ç™º", "4005": "æ˜­å’Œé›»å·¥", "2768": "åŒæ—¥",
        "9461": "ç™¾äº”éŠ€è¡Œ", "1820": "ãƒ«ãƒŸãƒŠã‚¹", "8725": "äº¬ç‹é›»é‰„", "9020": "JRæ±æ—¥æœ¬",
        "5108": "ãƒ–ãƒªãƒ‚ã‚¹ãƒˆãƒ³", "7012": "å·å´é‡å·¥", "7272": "ãƒ¤ãƒãƒç™º", "5214": "æ—¥æœ¬é›»æ°—ç¡å­",
        "6645": "ã‚ªãƒ ãƒ­ãƒ³", "6674": "ã‚¸ã‚ªãƒãƒ†ãƒƒã‚¯", "7741": "HOYA", "9022": "è¿‘é‰„ã‚°ãƒ«ãƒ¼ãƒ—",
        "9101": "æ—¥æœ¬éƒµèˆ¹", "9104": "å•†èˆ¹ä¸‰äº•", "9107": "å·å´æ±½èˆ¹", "6098": "ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ",
        "3086": "J.ãƒ•ãƒ­ãƒ³ãƒˆ", "8252": "ä¸¸äº•ã‚°ãƒ«ãƒ¼ãƒ—", "8233": "é«˜å³¶å±‹", "9984": "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯",
        "6701": "NEC", "8630": "é‡æ‘è¨¼åˆ¸", "8633": "å¤§å’Œè¨¼åˆ¸", "6869": "ã‚·ã‚¹ãƒ¡ãƒƒã‚¯ã‚¹",
        "4755": "æ¥½å¤©", "9999": "ä¼šç¤¾A",  # ãƒ€ãƒŸãƒ¼
        # ç±³å›½ - ä¸»è¦ 500
        "AAPL": "Apple", "MSFT": "Microsoft", "GOOGL": "Google", "AMZN": "Amazon",
        "NVDA": "Nvidia", "META": "Meta", "TSLA": "Tesla", "BRK.B": "Berkshire",
        "JPM": "JPMorgan", "V": "Visa", "JNJ": "J&J", "WMT": "Walmart",
        "MA": "Mastercard", "PG": "Procter", "PYPL": "PayPal", "INTC": "Intel",
        "AMD": "AMD", "CSCO": "Cisco", "ORCL": "Oracle", "IBM": "IBM",
        "ADBE": "Adobe", "CRM": "Salesforce", "NFLX": "Netflix", "DIS": "Disney",
        "BA": "Boeing", "CAT": "Caterpillar", "GE": "GE", "HON": "Honeywell",
        "MMM": "3M", "LMT": "Lockheed", "RTX": "Raytheon", "TXN": "Texas Inst",
        "QCOM": "Qualcomm", "AVGO": "Broadcom", "MU": "Micron", "CRM": "Salesforce",
        "COIN": "Coinbase", "NFLX": "Netflix", "ROKU": "Roku", "SPOT": "Spotify",
        "ZM": "Zoom", "SHOP": "Shopify", "UBER": "Uber", "LYFT": "Lyft",
        "ARKK": "Ark Innovation", "QQQ": "Nasdaq 100", "SPY": "S&P 500", "IVV": "iShares",
        "XOM": "ExxonMobil", "CVX": "Chevron", "COP": "ConocoPhillips", "EOG": "EOG",
        "MPC": "Marathon", "PSX": "Phillips 66", "SLB": "Schlumberger", "HAL": "Halliburton",
        "FDX": "FedEx", "UPS": "UPS", "DAL": "Delta", "UAL": "United",
        "LUV": "Southwest", "AAL": "American", "ALK": "Alaska", "SAVE": "Spirit",
        "MGM": "MGM", "WYNN": "Wynn", "LVS": "Las Vegas", "CZR": "Caesars",
        "HLT": "Hilton", "RCL": "Royal", "CCL": "Carnival", "F": "Ford",
        "GM": "GM", "TM": "Toyota", "HMC": "Honda", "SNE": "Sony", "TSM": "TSMC",
        "ASML": "ASML", "SAP": "SAP", "UBER": "Uber", "AI": "C3 Metrics",
        "MSTR": "MicroStrategy", "RIOT": "Riot", "MARA": "Marathon Digital",
        "SQ": "Block", "HOOD": "Robinhood", "TD": "TD", "RY": "RBC",
        "BNS": "BMO", "CM": "CIBC", "EIF": "Empire State", "BBY": "Best Buy",
        "TGT": "Target", "COST": "Costco", "HD": "Home Depot", "LOW": "Lowe's",
        "NKE": "Nike", "MCD": "McDonald's", "SBUX": "Starbucks", "YUM": "Yum",
        "CMG": "Chipotle", "KO": "Coca-Cola", "PEP": "PepsiCo", "MDLZ": "Mondelez",
        "KHC": "Kraft", "TSCO": "Tractor", "LB": "L Brands", "GPS": "Gap",
        "AZO": "AutoZone", "O": "Realty", "PLD": "Prologis", "AMT": "American",
        "CCI": "Crown", "DLR": "Digital", "EQIX": "Equinix", "UNIT": "Uniti",
    }
    return default_stocks

def load_stocks_from_cache():
    """JSONã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€(ãªã‘ã‚Œã°ä½œæˆ)"""
    if os.path.exists(STOCKS_CACHE_FILE):
        try:
            with open(STOCKS_CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            pass
    
    # JSONã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã‘ã‚Œã°ã€fetch_all_stocks()ã§å–å¾—ã—ã¦ä¿å­˜
    stocks = fetch_all_stocks()
    try:
        with open(STOCKS_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(stocks, f, ensure_ascii=False, indent=2)
    except Exception:
        pass
    return stocks

def init_db():
    """DB ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œã‚‹(ãªã‘ã‚Œã°)"""
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS price_cache (
            ticker TEXT,
            date TEXT,
            close REAL,
            volume REAL,
            PRIMARY KEY (ticker, date)
        )
    """)
    cur.execute("""
        CREATE TABLE IF NOT EXISTS fear_greed (
            date TEXT PRIMARY KEY,
            value INTEGER
        )
    """)
    cur.execute("""
        CREATE TABLE IF NOT EXISTS ticker_cache (
            ticker TEXT PRIMARY KEY,
            name TEXT,
            cached_at TEXT
        )
    """)
    
    # JSONã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥
    try:
        cur.execute("SELECT COUNT(*) FROM ticker_cache")
        count = cur.fetchone()[0]
        if count == 0:  # åˆå›ã®ã¿
            timestamp = datetime.today().isoformat()
            all_stocks = load_stocks_from_cache()
            for ticker, name in all_stocks.items():
                cur.execute("""
                    INSERT OR REPLACE INTO ticker_cache (ticker, name, cached_at)
                    VALUES (?, ?, ?)
                """, (ticker, name, timestamp))
            conn.commit()
    except Exception:
        pass
    
    conn.close()

def save_prices(ticker: str, df: pd.DataFrame):
    """price_cache ã« INSERT OR REPLACE ã§ä¿å­˜"""
    if df is None or df.empty:
        return
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    rows = []
    for idx, row in df[['Close', 'Volume']].iterrows():
        date = idx.strftime("%Y-%m-%d")
        close = None if pd.isna(row['Close']) else float(row['Close'])
        vol = None if pd.isna(row['Volume']) else float(row['Volume'])
        rows.append((ticker, date, close, vol))
    if rows:
        cur.executemany("""
            INSERT OR REPLACE INTO price_cache (ticker, date, close, volume)
            VALUES (?, ?, ?, ?)
        """, rows)
        conn.commit()
    conn.close()

def load_prices_from_db(ticker: str, start_date: str) -> pd.DataFrame:
    """DB ã‹ã‚‰æŒ‡å®š start_date ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query("""
        SELECT date, close, volume
        FROM price_cache
        WHERE ticker = ? AND date >= ?
        ORDER BY date
    """, conn, params=(ticker, start_date))
    conn.close()
    if df.empty:
        return pd.DataFrame()
    df['date'] = pd.to_datetime(df['date'])
    df = df.set_index('date')
    df.rename(columns={'close': 'Close', 'volume': 'Volume'}, inplace=True)
    return df

def update_price_if_needed(ticker: str, period: str = "1y") -> pd.DataFrame:
    """yfinanceå–å¾—+DBæ›´æ–°"""
    init_db()
    today = datetime.today().date()
    if period == "max":
        start_date = "1900-01-01"
    else:
        mapping = {"1y": 365, "3y": 365*3, "5y": 365*5, "10y": 365*10, "3mo":90, "6mo":180, "2y":365*2}
        days = mapping.get(period, 365)
        start_date = (today - timedelta(days=days)).strftime("%Y-%m-%d")
    local = load_prices_from_db(ticker, start_date)
    need_fetch = local.empty or local.index.max().date() < today
    if need_fetch:
        try:
            df_new = yf.Ticker(ticker).history(period=period)
            if df_new is None or df_new.empty:
                return local
            df_new.index = pd.to_datetime(df_new.index).tz_localize(None)
            save_prices(ticker, df_new)
            combined = load_prices_from_db(ticker, start_date)
            if combined.empty:
                df_new = df_new[['Close', 'Volume']].copy()
                return df_new
            return combined
        except Exception:
            return local
    else:
        return local

@st.cache_data(ttl=86400)   # 24æ™‚é–“ãƒ­ãƒ¼ã‚«ãƒ«DBã®ã¿ä½¿ç”¨
def load_price_cached(ticker: str, period: str = "1y") -> pd.DataFrame:
    return update_price_if_needed(ticker, period)

@st.cache_data
def get_company_name(ticker: str) -> str:
    """ä¼šç¤¾åã‚’å–å¾—(ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œ)"""
    try:
        info = yf.Ticker(ticker).info
        name = info.get('longName') or info.get('shortName') or ticker
        return name
    except Exception:
        return ticker

# ã‚»ã‚¯ã‚¿ãƒ¼ãƒ»æ¥­ç•Œåˆ¥ETFãƒãƒƒãƒ”ãƒ³ã‚°
SECTOR_ETF_MAP = {
    'Technology': 'XLK',
    'Healthcare': 'XLV',
    'Financials': 'XLF',
    'Industrials': 'XLI',
    'Energy': 'XLE',
    'Consumer Cyclical': 'XLY',
    'Consumer Defensive': 'XLP',
    'Real Estate': 'XLRE',
    'Utilities': 'XLU',
    'Basic Materials': 'XLB',
    'Unknown': None
}
# æ—¥æœ¬æ ª TOPIX-17 æ¥­ç¨®åˆ¥ETF(æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ç”¨)
TOPIX17_ETF_MAP = {
    "Energy": "1618",            # ã‚¨ãƒãƒ«ã‚®ãƒ¼è³‡æº
    "Materials": "1617",         # ç´ æãƒ»åŒ–å­¦
    "Industrials": "1610",       # é›»æ°—æ©Ÿå™¨
    "Consumer Cyclical": "1612", # è‡ªå‹•è»Šãƒ»è¼¸é€æ©Ÿ
    "Consumer Defensive": "1613",# é£Ÿå“
    "Healthcare": "1638",        # åŒ»è–¬å“
    "Financials": "1615",        # éŠ€è¡Œ
    "Real Estate": "1633",       # ä¸å‹•ç”£
    "Utilities": "1627",         # é›»åŠ›ãƒ»ã‚¬ã‚¹
}


@st.cache_data
def get_sector_avg_per() -> dict:
    """ã‚»ã‚¯ã‚¿ãƒ¼ETFã®PERã‹ã‚‰æ¥­ç•Œåˆ¥å¹³å‡PERã‚’å–å¾—(ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œ)"""
    sector_avg = {}
    for sector, etf in SECTOR_ETF_MAP.items():
        if etf is None:
            continue
        try:
            info = yf.Ticker(etf).info
            per = info.get('trailingPE') or info.get('forwardPE')
            if per is not None:
                sector_avg[sector] = per
        except Exception:
            pass
    return sector_avg

@st.cache_data
def get_financial_metrics(ticker: str) -> dict:
    """
    yfinance ã‚’åŸºæœ¬ã«ã—ã¤ã¤ã€EPS ãŒå£Šã‚Œã¦ã„ãŸã‚‰ FMP ã§è£œå®Œã™ã‚‹å®‰å…¨ç‰ˆã€‚
    forwardPE ã¯çµ¶å¯¾ã«ä½¿ã‚ãªã„ã€‚
    å…¬é–‹ã‚¢ãƒ—ãƒªã§ã‚‚ APIã‚­ãƒ¼ãŒæ¼ã‚Œãªã„ã‚ˆã† secrets ã‹ã‚‰å–å¾—ã™ã‚‹ã€‚
    """
    per = None
    pbr = None
    sector = "Unknown"

    # --- 1 yfinance ã§å–å¾— ---
    try:
        info = yf.Ticker(ticker).info
        price_yf = info.get("regularMarketPrice")
        eps_yf = info.get("epsTrailingTwelveMonths")
        pbr = info.get("priceToBook")
        sector = info.get("sector", "Unknown")

        # EPS ãŒæ­£å¸¸ãªã‚‰ PER ã‚’è¨ˆç®—
        if price_yf and eps_yf and eps_yf > 0:
            per = price_yf / eps_yf

    except Exception:
        pass

    # --- 2 FMP ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯(yfinance ãŒå£Šã‚Œã¦ã„ãŸå ´åˆã®ã¿) ---
    if per is None:
        try:
            # secrets ã‹ã‚‰ APIã‚­ãƒ¼ã‚’å–å¾—(å…¬é–‹ã‚¢ãƒ—ãƒªã§ã‚‚å®‰å…¨)
            api_key = st.secrets["FMP_API_KEY"]

            # æ—¥æœ¬æ ªã¯ .T ã‚’ä»˜ã‘ã‚‹
            fmp_ticker = ticker if "." in ticker else f"{ticker}.T"

            url = f"https://financialmodelingprep.com/api/v3/profile/{fmp_ticker}?apikey={api_key}"
            r = requests.get(url, timeout=5).json()

            if r:
                data = r[0]
                eps_fmp = data.get("eps")
                price_fmp = data.get("price")
                pbr_fmp = data.get("priceToBook")
                sector_fmp = data.get("sector")

                # FMP ã® EPS ãŒæ­£å¸¸ãªã‚‰ PER ã‚’è¨ˆç®—
                if price_fmp and eps_fmp and eps_fmp > 0:
                    per = price_fmp / eps_fmp

                # PBR è£œå®Œ
                if pbr is None and pbr_fmp:
                    pbr = pbr_fmp

                # ã‚»ã‚¯ã‚¿ãƒ¼è£œå®Œ
                if sector == "Unknown" and sector_fmp:
                    sector = sector_fmp

        except Exception:
            pass

    return {
        "PER": per,
        "PBR": pbr,
        "sector": sector
    }



def search_tickers(query: str) -> dict:
    """ä¼šç¤¾åã¾ãŸã¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‹ã‚‰æ¤œç´¢(è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯¾å¿œ)"""
    query_lower = query.lower().strip()
    if not query_lower:
        return {}
    
    results = {}
    init_db()  # DBåˆæœŸåŒ–(ãƒ‡ãƒ¼ã‚¿ãŒãªã‘ã‚Œã°æŠ•å…¥)
    
    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ¤œç´¢
    try:
        conn = sqlite3.connect(DB_PATH)
        # ãƒ†ã‚£ãƒƒã‚«ãƒ¼å®Œå…¨ä¸€è‡´(å„ªå…ˆåº¦é«˜)
        df_exact = pd.read_sql_query("""
            SELECT ticker, name FROM ticker_cache 
            WHERE LOWER(ticker) = ?
        """, conn, params=(query_lower,))
        
        for _, row in df_exact.iterrows():
            results[row['ticker']] = row['name']
        
        # éƒ¨åˆ†ä¸€è‡´(ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã¨åå‰)
        df_partial = pd.read_sql_query("""
            SELECT ticker, name FROM ticker_cache 
            WHERE LOWER(ticker) LIKE ? OR LOWER(name) LIKE ?
            LIMIT 15
        """, conn, params=(f"%{query_lower}%", f"%{query_lower}%"))
        conn.close()
        
        for _, row in df_partial.iterrows():
            if row['ticker'] not in results:  # é‡è¤‡é™¤å»
                results[row['ticker']] = row['name']
    except Exception:
        pass
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€yfinanceã§ç›´æ¥æ¤œç´¢(ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ã¿)
    if not results and (len(query_lower) <= 6 and query_lower.isalnum()):
        try:
            # æ—¥æœ¬æ ªã®å ´åˆã¯ .T ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’è©¦ã™
            test_tickers = [query_lower]
            if query_lower.isdigit():
                test_tickers.append(f"{query_lower}.T")
            
            for test_ticker in test_tickers:
                try:
                    info = yf.Ticker(test_ticker).info
                    if info and info.get('regularMarketPrice'):  # æœ‰åŠ¹ãªãƒ†ã‚£ãƒƒã‚«ãƒ¼
                        name = info.get('longName') or info.get('shortName') or test_ticker
                        results[test_ticker] = name
                        break
                except Exception:
                    pass
        except Exception:
            pass
    
    return results

def add_ticker_to_cache(ticker: str, name: str):
    """ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’JSONã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ """
    try:
        stocks = load_stocks_from_cache()
        if ticker not in stocks:
            stocks[ticker] = name
            with open(STOCKS_CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump(stocks, f, ensure_ascii=False, indent=2)
            
            # SQLiteã«ã‚‚è¿½åŠ 
            conn = sqlite3.connect(DB_PATH)
            cur = conn.cursor()
            timestamp = datetime.today().isoformat()
            cur.execute("""
                INSERT OR REPLACE INTO ticker_cache (ticker, name, cached_at)
                VALUES (?, ?, ?)
            """, (ticker, name, timestamp))
            conn.commit()
            conn.close()
            return True
    except Exception as e:
        return False
    return False

def load_fear_greed_cached() -> pd.DataFrame:
    """Fear & Greed Index å–å¾—(ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œ)"""
    init_db()
    conn = sqlite3.connect(DB_PATH)
    df_local = pd.read_sql_query("SELECT date, value FROM fear_greed ORDER BY date", conn)
    conn.close()
    if not df_local.empty:
        df_local['date'] = pd.to_datetime(df_local['date'])
        df_local = df_local.set_index('date')
        df_local.rename(columns={'value': 'Value'}, inplace=True)
        if df_local.index.max().date() >= (datetime.today().date() - timedelta(days=2)):
            return df_local
    try:
        url = "https://api.alternative.me/fng/?limit=0&format=json"
        res = requests.get(url, timeout=10)
        res.raise_for_status()
        data = res.json()
        df = pd.DataFrame(data.get("data", []))
        if df.empty:
            return df_local if not df_local.empty else pd.DataFrame()
        df["timestamp"] = pd.to_datetime(df["timestamp"].astype(int), unit="s")
        df["value"] = df["value"].astype(int)
        df_new = df[["timestamp", "value"]].rename(columns={"timestamp": "date"})
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute("DELETE FROM fear_greed")
        rows = [(r['date'].strftime("%Y-%m-%d"), int(r['value'])) for _, r in df_new.iterrows()]
        if rows:
            cur.executemany("INSERT OR REPLACE INTO fear_greed (date, value) VALUES (?, ?)", rows)
        conn.commit()
        conn.close()
        df_new = df_new.set_index('date').sort_index()
        df_new.rename(columns={'value': 'Value'}, inplace=True)
        return df_new
    except Exception as e:
        st.warning(f"Fear & Greed Indexå–å¾—å¤±æ•—: {e}")
        return df_local if not df_local.empty else pd.DataFrame()


# ============================
# UIéƒ¨åˆ†
# ============================
st.title("ğŸ“ˆ æ ªä¾¡æ¯”è¼ƒ + æŠ•è³‡å®¶å¿ƒç†æŒ‡æ¨™")

# ==== éŠ˜æŸ„å…¥åŠ›(ä¼šç¤¾åæ¤œç´¢å¯¾å¿œ) ====
st.subheader("éŠ˜æŸ„ã‚’æ¤œç´¢")

if "selected_tickers" not in st.session_state:
    st.session_state.selected_tickers = []
if "search_results" not in st.session_state:
    st.session_state.search_results = {}

search_query = st.text_input(
    "ä¼šç¤¾åã¾ãŸã¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚·ãƒ³ãƒœãƒ«ã§æ¤œç´¢ (ä¾‹: ãƒˆãƒ¨ã‚¿, Apple, 7203)",
    placeholder="ä¼šç¤¾åã¾ãŸã¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’å…¥åŠ›"
)

if search_query and len(search_query) > 0:
    with st.spinner("æ¤œç´¢ä¸­..."):
        st.session_state.search_results = search_tickers(search_query)
    
    if st.session_state.search_results:
        st.write("**æ¤œç´¢çµæœ:**")
        for symbol, name in list(st.session_state.search_results.items())[:5]:
            col1, col2, col3 = st.columns([2.5, 1, 1])
            with col1:
                st.write(f"**{symbol}** - {name}")
            with col2:
                if st.button("è¿½åŠ ", key=f"btn_{symbol}"):
                    ticker_to_add = f"{symbol}.T" if symbol.isdigit() else symbol
                    if ticker_to_add not in st.session_state.selected_tickers:
                        st.session_state.selected_tickers.append(ticker_to_add)
                    st.rerun()
            with col3:
                if st.button("è¾æ›¸ã«è¿½åŠ ", key=f"cache_{symbol}"):
                    if add_ticker_to_cache(symbol, name):
                        st.success(f"âœ“ {symbol} ã‚’è¾æ›¸ã«è¿½åŠ ã—ã¾ã—ãŸ")
                    else:
                        st.info(f"{symbol} ã¯æ—¢ã«è¾æ›¸ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™")

# é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã‚’è¡¨ç¤º
if st.session_state.selected_tickers:
    st.write("**é¸æŠä¸­ã®éŠ˜æŸ„:**")
    cols = st.columns(len(st.session_state.selected_tickers) + 1)
    for i, ticker in enumerate(st.session_state.selected_tickers):
        with cols[i]:
            col_name, col_remove = st.columns([4, 1])
            company_name = get_company_name(ticker)
            with col_name:
                st.write(f"â€¢ {company_name} ({ticker})")
            with col_remove:
                if st.button("å‰Šé™¤", key=f"remove_{ticker}"):
                    st.session_state.selected_tickers.remove(ticker)
                    st.rerun()

tickers = st.session_state.selected_tickers
codes = [t.replace(".T", "") if t.endswith(".T") else t for t in tickers]

# ==== æœŸé–“ã¨æ—¥ä»˜æŒ‡å®š ====
col1, col2, col3 = st.columns(3)
with col1:
    period = st.selectbox("ğŸ“… å–å¾—æœŸé–“", ["1y", "3y", "5y", "10y", "max"], index=4)
with col2:
    default_date = datetime.today().replace(year=datetime.today().year - 1)
    base_date = st.date_input("åŸºæº–æ—¥ã‚’é¸æŠ", value=default_date)
    base_ts = pd.to_datetime(base_date)
with col3:
    end_date = st.date_input("çµ‚äº†æ—¥ã‚’é¸æŠ", value=datetime.today())
    end_ts = pd.to_datetime(end_date)

if end_ts < base_ts:
    st.error("âŒ çµ‚äº†æ—¥ã¯åŸºæº–æ—¥ä»¥é™ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ==== æŠ•è³‡å®¶å¿ƒç†æŒ‡æ¨™é¸æŠ ====
sentiment_catalog = {
    "VIXæŒ‡æ•°": "^VIX",
    "VIX3M": "^VIX3M",
    "VVIX(VIXã®ãƒœãƒ©)": "^VVIX",
    "ãƒ‰ãƒ«æŒ‡æ•° DXY": "DX-Y.NYB",
    "Fear & Greed Index": "FNG",
    "ä¿¡ç”¨ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰(HYG-TLT)": "CREDIT_SPREAD",
    "ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åã‚Š(VIX/VVIX)": "VOL_BIAS",
    "ç±³10å¹´å‚µåˆ©å›ã‚Š": "^TNX"
}

sentiment_options = list(sentiment_catalog.keys())
selected_sentiments = st.multiselect(
    "ğŸ’¡ å¿ƒç†æŒ‡æ¨™ã‚’é¸æŠã—ã¦ãã ã•ã„(ç¬¬äºŒè»¸ã«è¡¨ç¤º)",
    sentiment_options,
    default=["VIXæŒ‡æ•°"]
)

# ==== ãƒ‡ãƒ¼ã‚¿å–å¾— ====
etf_data = {}
company_names = {}

for ticker, code in zip(tickers, codes):
    df = load_price_cached(ticker, period)
    if df.empty:
        continue
    df = df[(df.index >= base_ts) & (df.index <= end_ts)]
    if df.empty:
        continue
    base_price = df["Close"].iloc[0]
    df_rel = df.copy()
    df_rel["Relative Price"] = df_rel["Close"] / base_price
    etf_data[code] = df_rel
    company_names[code] = get_company_name(ticker)

# å¿ƒç†æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿å–å¾—
sentiment_data = {}
for name in selected_sentiments:
    code = sentiment_catalog[name]
    
    if code == "FNG":
        df = load_fear_greed_cached()
    elif code == "CREDIT_SPREAD":
        df_hyg = load_price_cached("HYG", period)
        df_tlt = load_price_cached("TLT", period)
        if not df_hyg.empty and not df_tlt.empty:
            df = pd.DataFrame(index=df_hyg.index)
            df["Value"] = df_hyg["Close"] / df_tlt["Close"]
        else:
            continue
    elif code == "VOL_BIAS":
        vix = load_price_cached("^VIX", period)
        vvix = load_price_cached("^VVIX", period)
        if not vix.empty and not vvix.empty:
            df = pd.DataFrame(index=vix.index)
            df["Value"] = vix["Close"] / vvix["Close"]
        else:
            continue
    else:
        df = load_price_cached(code, period)
        if df.empty:
            continue
        df["Value"] = df["Close"]
    
    df = df[(df.index >= base_ts) & (df.index <= end_ts)]
    if df.empty:
        continue
    
    sentiment_data[name] = df

# ==== æ—¥æœ¬æ ªæ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰(TOPIX-17)ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ ====
show_topix17 = st.checkbox("ğŸ“Š æ—¥æœ¬æ ªã®æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰(TOPIX-17 ETF)ã‚’è¡¨ç¤ºã™ã‚‹", value=False)
# ==== ã‚°ãƒ©ãƒ•ç”Ÿæˆ ====
if not etf_data and not sentiment_data:
    st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®éŠ˜æŸ„ã§ãŠè©¦ã—ãã ã•ã„ã€‚")
else:
    fig = go.Figure()

    # ç¬¬ä¸€è»¸:æ ªä¾¡(ç›¸å¯¾ä¾¡æ ¼)
    for code, df in etf_data.items():
        display_name = company_names.get(code, code)
        fig.add_trace(go.Scatter(
            x=df.index,
            y=df["Relative Price"],
            mode="lines",
            name=display_name,
            yaxis="y",
            hovertemplate="%{x|%Y-%m-%d}<br>" + display_name + ": %{y:.2f}x<extra></extra>"
        ))

    # ==== æ—¥æœ¬æ ª TOPIX-17 æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰(è£œåŠ©ç·š) ====
    if show_topix17 and len(etf_data) > 0:
        for sector_name, etf_code in TOPIX17_ETF_MAP.items():
            ticker = f"{etf_code}.T"
            df_topix = load_price_cached(ticker, period)
            if df_topix.empty:
                continue

            df_topix = df_topix[(df_topix.index >= base_ts) & (df_topix.index <= end_ts)]
            if df_topix.empty:
                continue

            base_price_topix = df_topix["Close"].iloc[0]
            df_topix["Relative Price"] = df_topix["Close"] / base_price_topix

            fig.add_trace(go.Scatter(
                x=df_topix.index,
                y=df_topix["Relative Price"],
                mode="lines",
                line=dict(dash="dot", width=1),
                name=f"TOPIX17 {sector_name}",
                yaxis="y",
                hovertemplate="%{x|%Y-%m-%d}<br>" + sector_name + ": %{y:.2f}x<extra></extra>"
            ))

    # ç¬¬äºŒè»¸:å¿ƒç†æŒ‡æ¨™
    sentiment_colors = {
        "VIXæŒ‡æ•°": "#FF6B6B",
        "VIX3M": "#FF8C42",
        "VVIX(VIXã®ãƒœãƒ©)": "#FFA500",
        "ãƒ‰ãƒ«æŒ‡æ•° DXY": "#4ECDC4",
        "Fear & Greed Index": "#95E1D3",
        "ä¿¡ç”¨ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰(HYG-TLT)": "#A8D8EA",
        "ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åã‚Š(VIX/VVIX)": "#AA96DA",
        "ç±³10å¹´å‚µåˆ©å›ã‚Š": "#A0DE82"
    }
    
    use_sentiment = st.checkbox("ğŸ’¡ æŠ•è³‡å®¶å¿ƒç†æŒ‡æ¨™ã‚’è¡¨ç¤ºã™ã‚‹", value=False)

    if use_sentiment:
        selected_sentiments = st.multiselect(
            "è¡¨ç¤ºã™ã‚‹å¿ƒç†æŒ‡æ¨™ã‚’é¸æŠ",
            sentiment_options,
            default=["VIXæŒ‡æ•°"]
        )
    else:
        selected_sentiments = []

    for name in selected_sentiments:
        if name not in sentiment_data:
            continue
        df = sentiment_data[name]
        color = sentiment_colors.get(name, "#999999")

        fig.add_trace(go.Scatter(
            x=df.index,
            y=df["Value"],
            mode="lines",
            line=dict(dash="dash", color=color, width=2),
            name=name,
            yaxis="y2",
            hovertemplate="%{x|%Y-%m-%d}<br>" + name + ": %{y:.2f}<extra></extra>"
        ))

    # Fear & Greed èƒŒæ™¯ã‚¾ãƒ¼ãƒ³
    if "Fear & Greed Index" in selected_sentiments and "Fear & Greed Index" in sentiment_data:
        fig.add_hrect(y0=0, y1=25, fillcolor="blue", opacity=0.1,
                      layer="below", line_width=0, yref="y2",
                      annotation_text="ææ€–", annotation_position="top left")
        fig.add_hrect(y0=75, y1=100, fillcolor="red", opacity=0.1,
                      layer="below", line_width=0, yref="y2",
                      annotation_text="å¼·æ¬²", annotation_position="top right")

    # VIX æŒ‡æ•°ã®ãƒªã‚¹ã‚¯å¸¯åŸŸ
    if "VIXæŒ‡æ•°" in selected_sentiments:
        fig.add_hrect(y0=0, y1=15, fillcolor="green", opacity=0.08,
                      layer="below", line_width=0, yref="y2")
        fig.add_hrect(y0=25, y1=80, fillcolor="red", opacity=0.08,
                      layer="below", line_width=0, yref="y2")

    # ==== ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š ====
    fig.update_layout(
        title=f"ğŸ“Š æ ªä¾¡ç›¸å¯¾æ¯”è¼ƒ ({base_date:%Y-%m-%d} ~ {end_date:%Y-%m-%d}) + æŠ•è³‡å®¶å¿ƒç†æŒ‡æ¨™",
        title_font_size=16,
        hovermode="x unified",
        height=600,
        yaxis=dict(
            title="<b>æ ªä¾¡æ¯”ç‡(åŸºæº–æ—¥=1.0)</b>",
            title_font_size=11,
            gridcolor="#E8E8E8"
        ),
        yaxis2=dict(
            title="<b>å¿ƒç†æŒ‡æ¨™å€¤</b>",
            title_font_size=11,
            overlaying="y",
            side="right"
        ),
        xaxis=dict(
            title="<b>æ—¥ä»˜</b>",
            title_font_size=11,
            gridcolor="#E8E8E8"
        ),
        legend=dict(
            orientation="h",
            yanchor="top",
            y=-0.2,
            xanchor="center",
            x=0.5,
            bgcolor="rgba(255, 255, 255, 0.8)",
            bordercolor="gray",
            borderwidth=1
        ),
        plot_bgcolor="rgba(250, 250, 250, 0.5)",
        paper_bgcolor="white",
        margin=dict(l=40, r=40, t=80, b=150)
    )

    config = {
        'responsive': True,
        'displayModeBar': True,
        'displaylogo': False,
        'modeBarButtonsToRemove': ['lasso2d']
    }
    st.plotly_chart(fig, use_container_width=True, config=config)
    # ==== ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ ====
    st.markdown("---")
    st.subheader("ğŸ“ˆ éŠ˜æŸ„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")

    # æ¥­ç•Œåˆ¥å¹³å‡PERã‚’å–å¾—
    sector_avg_per = get_sector_avg_per()

    # ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
    table_data = []

    for ticker, code in zip(tickers, codes):
        if code not in etf_data:
            continue
        df = etf_data[code]
        performance = ((df["Relative Price"].iloc[-1] - 1) * 100)
        base_price = df["Close"].iloc[0]
        end_price = df["Close"].iloc[-1]
        display_name = company_names.get(code, code)

        # PER, PBRã‚’å–å¾—
        metrics = get_financial_metrics(ticker)
        per = metrics['PER']
        pbr = metrics['PBR']
        sector = metrics['sector']

        per_str = f"{per:.2f}" if per is not None else "N/A"
        pbr_str = f"{pbr:.2f}" if pbr is not None else "N/A"

        # ã‚»ã‚¯ã‚¿ãƒ¼æ¥­ç•Œå¹³å‡ã‚’å–å¾—
        sector_avg_per_val = sector_avg_per.get(sector, None)
        sector_avg_str = f"{sector_avg_per_val:.2f}" if sector_avg_per_val is not None else "N/A"

        if code.isdigit():
            table_data.append({
                "éŠ˜æŸ„": display_name,
                "ã‚»ã‚¯ã‚¿ãƒ¼": sector,
                "å§‹å€¤": f"Â¥{base_price:,.0f}",
                "çµ‚å€¤": f"Â¥{end_price:,.0f}",
                "å¤‰åŒ–ç‡": f"{performance:+.2f}%",
                "PER": per_str,
                "æ¥­ç•Œå¹³å‡PER": sector_avg_str,
                "PBR": pbr_str
            })
        else:
            table_data.append({
                "éŠ˜æŸ„": display_name,
                "ã‚»ã‚¯ã‚¿ãƒ¼": sector,
                "å§‹å€¤": f"${base_price:,.2f}",
                "çµ‚å€¤": f"${end_price:,.2f}",
                "å¤‰åŒ–ç‡": f"{performance:+.2f}%",
                "PER": per_str,
                "æ¥­ç•Œå¹³å‡PER": sector_avg_str,
                "PBR": pbr_str
            })

    if table_data:
        df_table = pd.DataFrame(table_data)
        st.dataframe(df_table, use_container_width=True, hide_index=True)

    # ã‚»ã‚¯ã‚¿ãƒ¼ETFæƒ…å ±ã‚’è¡¨ç¤º
    st.markdown("---")
    st.subheader("ğŸ“Š ã‚»ã‚¯ã‚¿ãƒ¼æ¥­ç•Œå¹³å‡PER(ETFãƒ™ãƒ¼ã‚¹)")
    st.caption("å„ã‚»ã‚¯ã‚¿ãƒ¼ã®æ¥­ç•Œå¹³å‡PERã¯ã€ä»¥ä¸‹ã®ã‚»ã‚¯ã‚¿ãƒ¼ETFã®PERã«åŸºã¥ã„ã¦ã„ã¾ã™")

    sector_etf_info = [
        ("Technology", "XLK", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ä¼æ¥­ETF(ç±³å›½)"),
        ("Healthcare", "XLV", "ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ä¼æ¥­ETF(ç±³å›½)"),
        ("Financials", "XLF", "é‡‘èä¼æ¥­ETF(ç±³å›½)"),
        ("Industrials", "XLI", "ç”£æ¥­ä¼æ¥­ETF(ç±³å›½)"),
        ("Energy", "XLE", "ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¼æ¥­ETF(ç±³å›½)"),
        ("Consumer Cyclical", "XLY", "æ¶ˆè²»è²¡ä¼æ¥­ETF(ç±³å›½)"),
        ("Consumer Defensive", "XLP", "ç”Ÿæ´»å¿…éœ€å“ä¼æ¥­ETF(ç±³å›½)"),
        ("Real Estate", "XLRE", "ä¸å‹•ç”£ä¼æ¥­ETF(ç±³å›½)"),
        ("Utilities", "XLU", "å…¬å…±äº‹æ¥­ä¼æ¥­ETF(ç±³å›½)"),
        ("Basic Materials", "XLB", "ç´ æä¼æ¥­ETF(ç±³å›½)"),
    ]

    sector_info_cols = st.columns(5)
    for i, (sector, etf, desc) in enumerate(sector_etf_info):
        with sector_info_cols[i % 5]:
            if sector in sector_avg_per and sector_avg_per[sector] is not None:
                per_val = sector_avg_per[sector]
                st.metric(sector, f"{per_val:.2f}",
                          help=f"{desc}\nETF: {etf}")
            else:
                st.metric(sector, "N/A", help=f"{desc}\nETF: {etf}")

    # å¿ƒç†æŒ‡æ¨™(æœ€æ–°å€¤)
    st.markdown("---")
    st.subheader("ğŸ’¡ å¿ƒç†æŒ‡æ¨™ (æœ€æ–°å€¤)")

    for name, df in list(sentiment_data.items()):
        latest = df["Value"].iloc[-1]
        st.write(f"**{name}**: {latest:.2f}")
